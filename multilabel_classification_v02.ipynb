{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca85b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multilabel OCT training notebook (TensorFlow 2.x)\n",
    "# Requirements: tensorflow >= 2.6, pandas, numpy, scikit-learn, matplotlib\n",
    "# Example: pip install tensorflow pandas scikit-learn matplotlib\n",
    "\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks, optimizers, losses, metrics\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -------------------------\n",
    "# USER CONFIG / PATHS\n",
    "# -------------------------\n",
    "TRAIN_CSV = \"/home/sutirtha/anaconda3/sutirtha_research_operations/OCT_Data/OCT_layerwise_classification_dataset_15k/oct_data_15k/train_test_val_split_csv/train.csv\"   # path to training csv (must have 'filename' + label columns)\n",
    "VAL_CSV   = \"/home/sutirtha/anaconda3/sutirtha_research_operations/OCT_Data/OCT_layerwise_classification_dataset_15k/oct_data_15k/train_test_val_split_csv/val.csv\"     # validation csv\n",
    "TEST_CSV  = \"/home/sutirtha/anaconda3/sutirtha_research_operations/OCT_Data/OCT_layerwise_classification_dataset_15k/oct_data_15k/train_test_val_split_csv/test.csv\"    # test csv\n",
    "IMAGE_DIR = \"/home/sutirtha/anaconda3/sutirtha_research_operations/OCT_Data/OCT_layerwise_classification_dataset_15k/oct_data_15k/data\"     # base folder that contains the image files\n",
    "\n",
    "IMG_SIZE = (224, 224)     # image size\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "BACKBONE = \"EfficientNetB4\"  # change to other tf.keras.applications if desired\n",
    "LEARNING_RATE = 1e-4\n",
    "DROPOUT_RATE = 0.4\n",
    "SEED = 42\n",
    "\n",
    "# Label columns provided by the user\n",
    "LABEL_COLUMNS = [\n",
    "    'Vitreomacular Traction(#D95030)',\n",
    "    'Epiretinal Membrane(ERM)(#EA899A)',\n",
    "    'Full Thickness Macular Hole(FTMH)(#F54021)',\n",
    "    'Lamellar Macular Hole(LMH)(#F3A505)',\n",
    "    'Pseudo Macular Hole(#79553D)',\n",
    "    'Intraretinal Fluid/Spongiform Edema(#EA899A)',\n",
    "    'Subretinal Fluid(IRL)(#B44C43)',\n",
    "    'Cystoid Macular Edema(CME)(#00BB2D)',\n",
    "    'Hyperreflective Intraretinal Foci(#EFA94A)',\n",
    "    'Subretinal Fluid(SRL)(#8673A1)',\n",
    "    'Subretinal Hyperreflective Material(SHRM)(#6A5D4D)',\n",
    "    'Drusen(#FAD201)',\n",
    "    'CNVM(#316650)',\n",
    "    'PED(#0E294B)',\n",
    "    'Normal'\n",
    "]\n",
    "\n",
    "NUM_CLASSES = len(LABEL_COLUMNS)\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# -------------------------\n",
    "# UTIL: load CSV and sanity checks\n",
    "# -------------------------\n",
    "def load_df(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if 'filename' not in df.columns:\n",
    "        raise ValueError(\"CSV must contain a 'filename' column with image file names/paths.\")\n",
    "    # Ensure label columns present. If not present, create columns with zeros (safer).\n",
    "    for c in LABEL_COLUMNS:\n",
    "        if c not in df.columns:\n",
    "            print(f\"Warning: label column {c} not found in {csv_path}. Filling with zeros.\")\n",
    "            df[c] = 0\n",
    "    # create absolute path column\n",
    "    df['filepath'] = df['filename'].apply(lambda x: os.path.join(IMAGE_DIR, str(x)))\n",
    "    # create multi-hot numpy arrays\n",
    "    df['labels_array'] = df[LABEL_COLUMNS].values.tolist()\n",
    "    return df\n",
    "\n",
    "train_df = load_df(TRAIN_CSV)\n",
    "val_df = load_df(VAL_CSV)\n",
    "test_df = load_df(TEST_CSV)\n",
    "\n",
    "print(\"Train samples:\", len(train_df))\n",
    "print(\"Val samples:\", len(val_df))\n",
    "print(\"Test samples:\", len(test_df))\n",
    "\n",
    "# -------------------------\n",
    "# Compute class frequencies & positive weights (pos_weight)\n",
    "# pos_weight = (#negatives / #positives) for each class — used with\n",
    "# tf.nn.weighted_cross_entropy_with_logits inside a custom loss.\n",
    "# -------------------------\n",
    "class_counts = train_df[LABEL_COLUMNS].sum(axis=0).astype(int)\n",
    "total_samples = len(train_df)\n",
    "neg_counts = total_samples - class_counts\n",
    "# avoid division by zero by clipping counts at 1\n",
    "pos_counts = class_counts.clip(lower=1)\n",
    "pos_weight = (neg_counts / pos_counts).astype(float).values  # shape (NUM_CLASSES,)\n",
    "\n",
    "print(\"Class counts (train):\")\n",
    "print(class_counts)\n",
    "print(\"pos_weight per class (neg/pos):\")\n",
    "for c, pw in zip(LABEL_COLUMNS, pos_weight):\n",
    "    print(f\"{c}: {pw:.3f}\")\n",
    "\n",
    "# -------------------------\n",
    "# Optionally do light upsampling of minority samples (probabilistic resampling)\n",
    "# This creates a new DataFrame 'train_df_balanced' by sampling with probability proportional to sample weight.\n",
    "# If you prefer NOT to upsample, simply set train_df_balanced = train_df\n",
    "# -------------------------\n",
    "def create_sample_weights(df, pos_weight_per_class):\n",
    "    # For each sample compute a sample weight = sum(pos_weight_of_each_positive_class) / (num_positive_labels+1e-6)\n",
    "    labels = np.array(df[LABEL_COLUMNS].values.tolist(), dtype=float)\n",
    "    # multiply each label by pos_weight and sum across classes\n",
    "    per_sample_score = (labels * pos_weight_per_class).sum(axis=1)\n",
    "    # normalize to [0,1]\n",
    "    if per_sample_score.max() - per_sample_score.min() > 0:\n",
    "        per_sample_score = (per_sample_score - per_sample_score.min()) / (per_sample_score.max() - per_sample_score.min())\n",
    "    else:\n",
    "        per_sample_score = np.ones_like(per_sample_score)\n",
    "    # add small constant to keep positives boosted\n",
    "    return per_sample_score + 0.1\n",
    "\n",
    "upsample = True   # set to False to skip resampling\n",
    "if upsample:\n",
    "    sample_scores = create_sample_weights(train_df, pos_weight)\n",
    "    # create a sampled DataFrame larger than original to partially balance classes\n",
    "    multiply_factor = 1.5  # how many times bigger the new train set will be (1.0 = no change)\n",
    "    n_new = int(len(train_df) * multiply_factor)\n",
    "    sampled_idx = np.random.choice(len(train_df), size=n_new, replace=True, p=sample_scores / sample_scores.sum())\n",
    "    train_df_balanced = train_df.iloc[sampled_idx].reset_index(drop=True)\n",
    "    print(f\"Upsampled train: from {len(train_df)} to {len(train_df_balanced)}\")\n",
    "else:\n",
    "    train_df_balanced = train_df\n",
    "\n",
    "# -------------------------\n",
    "# TF Dataset pipeline\n",
    "# -------------------------\n",
    "def read_image(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.io.decode_image(img, channels=3, expand_animations=False)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)  # 0..1\n",
    "    img = tf.image.resize(img, IMG_SIZE)\n",
    "    return img\n",
    "\n",
    "# Augmentations for training\n",
    "def augment_image(image):\n",
    "    # Random flip\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    # Random rotation by small angle\n",
    "    angle = tf.random.uniform([], -0.08, 0.08)  # radians (~ +/- 4.5 deg)\n",
    "    image = tfa_image_rotate(image, angle)\n",
    "    # Random brightness/contrast\n",
    "    image = tf.image.random_brightness(image, 0.08)\n",
    "    image = tf.image.random_contrast(image, 0.9, 1.1)\n",
    "    # random zoom / crop and resize back\n",
    "    if tf.random.uniform([]) < 0.3:\n",
    "        crop = tf.image.random_crop(image, size=[int(IMG_SIZE[0]*0.9), int(IMG_SIZE[1]*0.9), 3])\n",
    "        image = tf.image.resize(crop, IMG_SIZE)\n",
    "    return image\n",
    "\n",
    "# small helper to rotate images (tf.image doesn't have rotate in base TF).\n",
    "def tfa_image_rotate(image, angle):\n",
    "    # We implement a small rotation using tf.keras.preprocessing if tfa isn't installed.\n",
    "    # Prefer using tensorflow-addons' image.rotate if available. We'll try to use tfa if installed.\n",
    "    try:\n",
    "        import tensorflow_addons as tfa\n",
    "        return tfa.image.rotate(image, angle)\n",
    "    except Exception:\n",
    "        # Fallback: approximate rotation by using affine transform via tf.keras.layers.experimental.preprocessing\n",
    "        # We'll just return image (no rotation) if tfa is not available — it's optional.\n",
    "        return image\n",
    "\n",
    "def make_dataset_from_df(df, shuffle=False, augment=False, batch_size=32):\n",
    "    filepaths = df['filepath'].values\n",
    "    labels = np.array(df[LABEL_COLUMNS].values.tolist(), dtype=np.float32)\n",
    "    ds = tf.data.Dataset.from_tensor_slices((filepaths, labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(df), seed=SEED)\n",
    "    def _load(path, label):\n",
    "        img = read_image(path)\n",
    "        if augment:\n",
    "            img = augment_image(img)\n",
    "        return img, label\n",
    "    ds = ds.map(_load, num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "train_ds = make_dataset_from_df(train_df_balanced, shuffle=True, augment=True, batch_size=BATCH_SIZE)\n",
    "val_ds = make_dataset_from_df(val_df, shuffle=False, augment=False, batch_size=BATCH_SIZE)\n",
    "test_ds = make_dataset_from_df(test_df, shuffle=False, augment=False, batch_size=BATCH_SIZE)\n",
    "\n",
    "# -------------------------\n",
    "# Model: EfficientNet backbone + head\n",
    "# -------------------------\n",
    "def build_model(img_size=IMG_SIZE, num_classes=NUM_CLASSES, dropout_rate=DROPOUT_RATE, backbone_name=BACKBONE, lr=LEARNING_RATE):\n",
    "    inputs = layers.Input(shape=(img_size[0], img_size[1], 3), name=\"image\")\n",
    "    # Use tf.keras.applications dynamically\n",
    "    backbone_constructor = getattr(tf.keras.applications, backbone_name)\n",
    "    backbone = backbone_constructor(include_top=False, weights='imagenet', input_tensor=inputs, pooling='avg')\n",
    "    x = backbone.output\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='sigmoid', name='predictions')(x)\n",
    "    model = models.Model(inputs=inputs, outputs=outputs)\n",
    "    optimizer = optimizers.Adam(learning_rate=lr)\n",
    "    return model, optimizer\n",
    "\n",
    "model, optimizer = build_model()\n",
    "model.summary()\n",
    "\n",
    "# -------------------------\n",
    "# Custom weighted loss for multilabel: uses pos_weight per class\n",
    "# Implementation uses logits; since our model outputs probabilities (sigmoid),\n",
    "# we will convert predictions to logits inside the loss or better: build model to give logits.\n",
    "# Simpler approach: create model with sigmoid as above, then use:\n",
    "# loss = sum( (1-label)*-log(1-p) + pos_weight*label*-log(p) ) / num_classes\n",
    "# We'll implement numerically stable version.\n",
    "# -------------------------\n",
    "pos_weight_tf = tf.constant(pos_weight, dtype=tf.float32)\n",
    "\n",
    "def weighted_bce_loss(y_true, y_pred):\n",
    "    # y_true, y_pred both are [batch, num_classes], y_pred in [0,1]\n",
    "    # Avoid log(0) numerically stable variant:\n",
    "    eps = 1e-7\n",
    "    y_pred = tf.clip_by_value(y_pred, eps, 1 - eps)\n",
    "    # compute component-wise: loss = - ( pos_weight * y_true * log(y_pred) + (1 - y_true) * log(1 - y_pred) )\n",
    "    pos_term = - (pos_weight_tf * y_true * tf.math.log(y_pred))\n",
    "    neg_term = - ((1.0 - y_true) * tf.math.log(1.0 - y_pred))\n",
    "    loss = pos_term + neg_term\n",
    "    # average across classes then across batch\n",
    "    loss = tf.reduce_mean(tf.reduce_mean(loss, axis=1))\n",
    "    return loss\n",
    "\n",
    "# Metrics: per-class AUC + micro/macro AUC would be useful\n",
    "# We'll add an overall micro AUC and per-class AUC metrics\n",
    "metric_list = [metrics.AUC(name=\"auc_micro\", multi_label=True)]\n",
    "# Add per-class AUC metrics (useful for monitoring)\n",
    "for i, cname in enumerate(LABEL_COLUMNS):\n",
    "    metric_list.append(metrics.AUC(name=f\"auc_{i}\"))\n",
    "\n",
    "# Compile\n",
    "model.compile(optimizer=optimizer, loss=weighted_bce_loss, metrics=metric_list)\n",
    "\n",
    "# -------------------------\n",
    "# Callbacks\n",
    "# -------------------------\n",
    "checkpoint_path = \"/home/sutirtha/anaconda3/sutirtha_research_operations/OCT_Data/OCT_layerwise_classification_dataset_15k/codes/models/efficientnetB4_with_normal_best_model.h5\"\n",
    "cb = [\n",
    "    callbacks.ModelCheckpoint(checkpoint_path, monitor='val_auc_micro', mode='max', save_best_only=True, verbose=1),\n",
    "    callbacks.EarlyStopping(monitor='val_auc_micro', mode='max', patience=6, restore_best_weights=True, verbose=1),\n",
    "    callbacks.ReduceLROnPlateau(monitor='val_auc_micro', factor=0.5, patience=3, verbose=1, mode='max', min_lr=1e-7)\n",
    "]\n",
    "\n",
    "# -------------------------\n",
    "# Fit\n",
    "# -------------------------\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=cb,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Utility: function for inference on single images\n",
    "# -------------------------\n",
    "# def infer_image(model, image_path, threshold=0.5):\n",
    "#     img = read_image(image_path)\n",
    "#     img = tf.expand_dims(img, axis=0)\n",
    "#     prob = model.predict(img)[0]\n",
    "#     labels = [LABEL_COLUMNS[i] for i in range(NUM_CLASSES) if prob[i] >= threshold]\n",
    "#     return prob, labels\n",
    "\n",
    "# Example usage:\n",
    "# probs, predicted_labels = infer_image(model, \"/path/to/some/image.png\", threshold=0.4)\n",
    "# print(predicted_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae05c178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Plot training curves\n",
    "# -------------------------\n",
    "def plot_history(hist):\n",
    "    dh = hist.history\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(dh['loss'], label='train_loss')\n",
    "    plt.plot(dh['val_loss'], label='val_loss')\n",
    "    plt.legend(); plt.title('Loss')\n",
    "    plt.subplot(1,2,2)\n",
    "    if 'auc_micro' in dh:\n",
    "        plt.plot(dh['auc_micro'], label='train_auc_micro')\n",
    "        plt.plot(dh['val_auc_micro'], label='val_auc_micro')\n",
    "        plt.legend(); plt.title('AUC micro')\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)\n",
    "\n",
    "# -------------------------\n",
    "# Evaluate on test set & prediction generation\n",
    "# -------------------------\n",
    "print(\"Loading best weights from:\", checkpoint_path)\n",
    "try:\n",
    "    model.load_weights(checkpoint_path)\n",
    "except Exception as e:\n",
    "    print(\"Could not load checkpoint:\", e)\n",
    "\n",
    "# Predict on test\n",
    "y_pred_prob = model.predict(test_ds, verbose=1)\n",
    "# Convert dataset labels to ground truth array\n",
    "y_true = np.vstack(test_df[LABEL_COLUMNS].values)\n",
    "\n",
    "# Compute per-class AUCs\n",
    "per_class_auc = []\n",
    "for i in range(NUM_CLASSES):\n",
    "    try:\n",
    "        auc_i = roc_auc_score(y_true[:, i], y_pred_prob[:, i])\n",
    "    except ValueError:\n",
    "        auc_i = float('nan')  # if only one class present in y_true\n",
    "    per_class_auc.append(auc_i)\n",
    "    print(f\"Class {LABEL_COLUMNS[i]} AUC: {auc_i:.4f}\")\n",
    "\n",
    "# Overall micro/macro AUC\n",
    "try:\n",
    "    micro_auc = roc_auc_score(y_true.ravel(), y_pred_prob.ravel(), average='micro')\n",
    "    macro_auc = np.nanmean(per_class_auc)\n",
    "    print(f\"Micro AUC (flattened): {micro_auc:.4f}, Macro AUC (mean of per-class): {macro_auc:.4f}\")\n",
    "except Exception as e:\n",
    "    print(\"Error computing overall AUC:\", e)\n",
    "\n",
    "# Binarize predictions at threshold (default 0.5) for classification report\n",
    "THRESH = 0.4\n",
    "y_pred_bin = (y_pred_prob >= THRESH).astype(int)\n",
    "\n",
    "print(\"Multilabel classification report (threshold=0.5):\")\n",
    "report = classification_report(y_true, y_pred_bin, target_names=LABEL_COLUMNS, zero_division=0)\n",
    "print(report)\n",
    "\n",
    "# Save predictions into test_df\n",
    "test_df_preds = test_df.copy()\n",
    "for i, c in enumerate(LABEL_COLUMNS):\n",
    "    test_df_preds[f\"pred_prob_{i}\"] = y_pred_prob[:, i]\n",
    "    test_df_preds[f\"pred_{i}\"] = y_pred_bin[:, i]\n",
    "# Optionally save\n",
    "test_df_preds.to_csv(\"test_predictions_with_probs.csv\", index=False)\n",
    "print(\"Saved predictions to test_predictions_with_probs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb829d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Detailed Evaluation: Confusion Matrices per Label\n",
    "# ============================================\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "# Compute confusion matrix for each label\n",
    "conf_matrices = {}\n",
    "for i, label in enumerate(LABEL_COLUMNS):\n",
    "    cm = confusion_matrix(y_true[:, i], y_pred_bin[:, i])\n",
    "    conf_matrices[label] = cm\n",
    "    tn, fp, fn, tp = cm.ravel() if cm.size == 4 else (0, 0, 0, 0)\n",
    "    print(f\"\\nLabel: {label}\")\n",
    "    print(f\"Confusion Matrix:\\n{cm}\")\n",
    "    print(f\"TP={tp}, FP={fp}, TN={tn}, FN={fn}\")\n",
    "    sensitivity = tp / (tp + fn + 1e-8)\n",
    "    specificity = tn / (tn + fp + 1e-8)\n",
    "    print(f\"Sensitivity (Recall): {sensitivity:.4f}, Specificity: {specificity:.4f}\")\n",
    "\n",
    "# ============================================\n",
    "# Classification Metrics Summary\n",
    "# ============================================\n",
    "precision, recall, f1, support = precision_recall_fscore_support(\n",
    "    y_true, y_pred_bin, average=None, zero_division=0\n",
    ")\n",
    "\n",
    "summary_df = pd.DataFrame({\n",
    "    'Label': LABEL_COLUMNS,\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1-score': f1,\n",
    "    'Support': support\n",
    "})\n",
    "\n",
    "overall_precision, overall_recall, overall_f1, _ = precision_recall_fscore_support(\n",
    "    y_true, y_pred_bin, average='micro', zero_division=0\n",
    ")\n",
    "print(\"\\n================ Overall Micro-Average Metrics ================\")\n",
    "print(f\"Precision: {overall_precision:.4f}, Recall: {overall_recall:.4f}, F1: {overall_f1:.4f}\")\n",
    "\n",
    "overall_precision, overall_recall, overall_f1, _ = precision_recall_fscore_support(\n",
    "    y_true, y_pred_bin, average='macro', zero_division=0\n",
    ")\n",
    "print(\"\\n================ Overall Macro-Average Metrics ================\")\n",
    "print(f\"Precision: {overall_precision:.4f}, Recall: {overall_recall:.4f}, F1: {overall_f1:.4f}\")\n",
    "\n",
    "print(\"\\nDetailed per-label metrics:\")\n",
    "display(summary_df)\n",
    "\n",
    "# ============================================\n",
    "# Plot Confusion Matrices as Heatmap Grid\n",
    "# ============================================\n",
    "import math\n",
    "\n",
    "num_labels = len(LABEL_COLUMNS)\n",
    "cols = 4\n",
    "rows = math.ceil(num_labels / cols)\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(20, 4 * rows))\n",
    "\n",
    "for idx, label in enumerate(LABEL_COLUMNS):\n",
    "    r, c = divmod(idx, cols)\n",
    "    ax = axes[r, c] if rows > 1 else axes[c]\n",
    "    cm = conf_matrices[label]\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, ax=ax)\n",
    "    ax.set_title(label)\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"Actual\")\n",
    "\n",
    "# Hide empty subplots if any\n",
    "for j in range(num_labels, rows * cols):\n",
    "    r, c = divmod(j, cols)\n",
    "    if rows > 1:\n",
    "        fig.delaxes(axes[r, c])\n",
    "    else:\n",
    "        fig.delaxes(axes[c])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d3d75e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5908cd86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2deee37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d9532d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a4fff3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
